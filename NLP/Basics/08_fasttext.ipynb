{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/1qEaNebZ97ZfAl7XiGey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrabaKDataScience/DeepLearning/blob/main/NLP/Basics/08_fasttext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install fast text module & Pre trained Model "
      ],
      "metadata": {
        "id": "cfsij_8G7W_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgzon456g0z7",
        "outputId": "99fe53b6-0c26-4431-e9bd-218fe5eee790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3157470 sha256=d7876a7c2ba24990bdd97ffb80fa762f7c89886652681f2fc1126ac2b285f229\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretrained english model\n",
        "\n",
        "Trained on Wikipedia and common crawl data"
      ],
      "metadata": {
        "id": "zpLQ0mp07dy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPgDFxl0hEjZ",
        "outputId": "0f31328a-cc16-4f9f-b727-b45d95833b06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-11 02:59:46--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: â€˜cc.en.300.bin.gz.1â€™\n",
            "\n",
            "cc.en.300.bin.gz.1  100%[===================>]   4.19G  20.6MB/s    in 3m 27s  \n",
            "\n",
            "2022-11-11 03:03:13 (20.8 MB/s) - â€˜cc.en.300.bin.gz.1â€™ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip cc.en.300.bin.gz"
      ],
      "metadata": {
        "id": "dQ-5YmuXpFG8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the model"
      ],
      "metadata": {
        "id": "0NZ2bpx07mub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.load_model('cc_en_300.bin')"
      ],
      "metadata": {
        "id": "tZT_GTzFpvi_",
        "outputId": "2be858d8-361b-4330-f812-9c3b5a6f5e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model)"
      ],
      "metadata": {
        "id": "XAHQwiqTp2yg",
        "outputId": "e3d8fb2a-9468-42f6-da81-0caa548ccaab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_labels',\n",
              " '_words',\n",
              " 'f',\n",
              " 'get_analogies',\n",
              " 'get_dimension',\n",
              " 'get_input_matrix',\n",
              " 'get_input_vector',\n",
              " 'get_label_id',\n",
              " 'get_labels',\n",
              " 'get_line',\n",
              " 'get_meter',\n",
              " 'get_nearest_neighbors',\n",
              " 'get_output_matrix',\n",
              " 'get_sentence_vector',\n",
              " 'get_subword_id',\n",
              " 'get_subwords',\n",
              " 'get_word_id',\n",
              " 'get_word_vector',\n",
              " 'get_words',\n",
              " 'is_quantized',\n",
              " 'labels',\n",
              " 'predict',\n",
              " 'quantize',\n",
              " 'save_model',\n",
              " 'set_args',\n",
              " 'set_matrices',\n",
              " 'test',\n",
              " 'test_label',\n",
              " 'words']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get nearest neighbors"
      ],
      "metadata": {
        "id": "fZB2Zq5Y7pF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors('good')"
      ],
      "metadata": {
        "id": "SvipMS_JqSET",
        "outputId": "07874fe5-2c9d-4a3f-8081-0b2af0813e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7517593502998352, 'bad'),\n",
              " (0.7426098585128784, 'great'),\n",
              " (0.7299689054489136, 'decent'),\n",
              " (0.7123614549636841, 'nice'),\n",
              " (0.6796907186508179, 'Good'),\n",
              " (0.6737031936645508, 'excellent'),\n",
              " (0.669592022895813, 'goood'),\n",
              " (0.6602178812026978, 'ggod'),\n",
              " (0.6479219794273376, 'semi-good'),\n",
              " (0.6417751908302307, 'good.Good')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> when you search for similar words for 'good' you get the word 'bad' also. \n",
        "> We get all the words used in similar context in the training data of the model"
      ],
      "metadata": {
        "id": "V3pZj6s4qkhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A look at the token / word vector"
      ],
      "metadata": {
        "id": "G7gBmfvm7tSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_word_vector('good')"
      ],
      "metadata": {
        "id": "t8lq8-awswXR",
        "outputId": "06ff91c6-1a99-4827-b78a-54d18b7cbede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.09213716, -0.0634383 ,  0.00173813,  0.13524324, -0.06561062,\n",
              "        0.00619071,  0.12609869, -0.01646539,  0.0174491 , -0.00126792,\n",
              "       -0.09709831,  0.02329333,  0.00996784,  0.00463419,  0.01587938,\n",
              "        0.00689824,  0.08575399, -0.01988525, -0.0601579 , -0.02327966,\n",
              "        0.01183712,  0.08217917,  0.01488847,  0.00902181,  0.00696296,\n",
              "       -0.06426616,  0.03345198, -0.02101481,  0.06767873,  0.03022419,\n",
              "        0.07203474, -0.05689922, -0.04370377,  0.00642597,  0.0439174 ,\n",
              "        0.0604848 , -0.00611545, -0.12256738, -0.03530414, -0.02696739,\n",
              "       -0.02058216,  0.00752347, -0.00686451,  0.0362783 , -0.03308735,\n",
              "        0.05801626,  0.00832448, -0.06336953, -0.05775082,  0.01089846,\n",
              "       -0.0925179 ,  0.01559984, -0.04079024,  0.0066871 , -0.06374165,\n",
              "        0.05881973,  0.07209535, -0.05387195, -0.14658651, -0.04046486,\n",
              "       -0.02507038, -0.04954465, -0.05224417, -0.06846938,  0.0467079 ,\n",
              "        0.00459271, -0.07522177,  0.03627685, -0.0698283 ,  0.0174791 ,\n",
              "       -0.03427085, -0.043176  ,  0.00764059,  0.05694873,  0.0064466 ,\n",
              "       -0.01078498,  0.02328758,  0.06951396,  0.05373847,  0.02533235,\n",
              "        0.04307906, -0.03298698, -0.01265992,  0.02883131,  0.01145704,\n",
              "       -0.03029559,  0.02814867,  0.09258693,  0.08908885,  0.21924517,\n",
              "        0.03836972,  0.05020344,  0.13716629, -0.00859585, -0.0113667 ,\n",
              "        0.10641211, -0.07889125,  0.08034115, -0.00441031, -0.04873084,\n",
              "        0.00183913,  0.06675661,  0.00995041,  0.03010932, -0.02987454,\n",
              "        0.02509423, -0.04333989, -0.0059728 , -0.00332469, -0.0522663 ,\n",
              "       -0.03281598,  0.12006998,  0.01166376, -0.03454734,  0.01907663,\n",
              "       -0.01262398, -0.02025696,  0.01866139,  0.05016267,  0.05604192,\n",
              "        0.04971652,  0.03597424, -0.00690809,  0.05734055,  0.05945349,\n",
              "        0.0261135 ,  0.01734888, -0.00711455, -0.1295353 ,  0.01600225,\n",
              "        0.00150194, -0.03631282, -0.00469453,  0.02215887, -0.00699799,\n",
              "       -0.02894606,  0.03908806,  0.0401371 , -0.03941151, -0.02646147,\n",
              "       -0.04718655,  0.02674983,  0.07485171,  0.03144611, -0.07028159,\n",
              "       -0.0424196 , -0.2054326 , -0.09083363, -0.01121964,  0.05520659,\n",
              "       -0.11916859,  0.00788128, -0.13444994, -0.01488061, -0.02091767,\n",
              "        0.09262317,  0.06291065, -0.02200251, -0.03655258,  0.02587264,\n",
              "        0.0447952 , -0.01287306, -0.0350248 , -0.02456109, -0.04746678,\n",
              "        0.00130645,  0.01147217, -0.00531678,  0.11162786,  0.0253936 ,\n",
              "       -0.03638908, -0.05931935, -0.00549408,  0.0074574 , -0.01289796,\n",
              "       -0.0719263 , -0.02486867, -0.04750141,  0.00194147, -0.1141203 ,\n",
              "        0.01648522,  0.05083858, -0.02679086, -0.04766015,  0.00518819,\n",
              "        0.04099732,  0.02709844, -0.06511603, -0.06652133, -0.07979076,\n",
              "        0.0491582 ,  0.05377757,  0.0200878 , -0.03799915, -0.02513728,\n",
              "        0.00410288, -0.04514588, -0.04708159, -0.00559349,  0.13073431,\n",
              "       -0.09549722,  0.16606593,  0.0221815 , -0.05887613, -0.02126267,\n",
              "        0.00425452, -0.05540022, -0.06286709, -0.05455609,  0.11610305,\n",
              "        0.12443443, -0.00741135,  0.01761745, -0.0075937 , -0.05616794,\n",
              "       -0.01676267,  0.07975771, -0.04046471,  0.07211975,  0.13321361,\n",
              "        0.07106   , -0.01443719,  0.02562447,  0.05690589, -0.0090815 ,\n",
              "       -0.00628489,  0.03647495,  0.00689165,  0.04463093,  0.01837448,\n",
              "        0.00218417, -0.02093561,  0.07896647, -0.05610979,  0.02535573,\n",
              "       -0.09674191, -0.03684152,  0.01628419,  0.00908958, -0.06135098,\n",
              "        0.05458912, -0.03850613,  0.03017449, -0.1417458 ,  0.17130415,\n",
              "       -0.05436675, -0.01079106,  0.04692602, -0.02894384, -0.0273016 ,\n",
              "        0.09735578, -0.13424474, -0.02024667, -0.04736632, -0.03244197,\n",
              "        0.00541304, -0.04343438, -0.0003211 ,  0.16816942,  0.03105447,\n",
              "       -0.03063404, -0.00045107,  0.04690041,  0.11270425, -0.13718411,\n",
              "        0.05740229,  0.00801181, -0.17329559,  0.03051268, -0.1268264 ,\n",
              "       -0.06074513, -0.03838078, -0.01737073,  0.12296247, -0.05316308,\n",
              "       -0.07613882,  0.02129988,  0.0121702 , -0.01287838,  0.0768657 ,\n",
              "       -0.26769733,  0.05321693, -0.12607867, -0.02812696,  0.07982896,\n",
              "       -0.02915069, -0.01767069, -0.10350563, -0.0471432 , -0.03033449,\n",
              "        0.08542065,  0.02928957, -0.11185424, -0.00142424,  0.0379483 ,\n",
              "        0.02438426, -0.01398861,  0.14165413, -0.05115522, -0.08859383],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each token will be a 300 dimension feature vector\n",
        "model.get_word_vector('good').shape"
      ],
      "metadata": {
        "id": "Upq-LvCJs8WU",
        "outputId": "901f3bde-089f-4bf2-b516-5cc82d05a85e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Explore the Analogies"
      ],
      "metadata": {
        "id": "5gsgAYop7z0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_analogies(\"berlin\",\"germany\",\"india\")"
      ],
      "metadata": {
        "id": "at1WA6AvtQsL",
        "outputId": "6433ebad-0855-4cd1-f4dc-a17d783f8019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7148876190185547, 'delhi'),\n",
              " (0.6974374055862427, 'mumbai'),\n",
              " (0.648612916469574, 'jaipur'),\n",
              " (0.6349966526031494, 'kolkata'),\n",
              " (0.6279922723770142, 'pune'),\n",
              " (0.6277596354484558, 'bangalore'),\n",
              " (0.6044078469276428, 'hyderabad'),\n",
              " (0.6021745800971985, 'noida'),\n",
              " (0.6018899083137512, 'bhubaneswar'),\n",
              " (0.599077582359314, 'nashik')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity measuring"
      ],
      "metadata": {
        "id": "XDs1YqVv74Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Beware that Uppercase and lower case are treated as being non similar ,\n",
        "# hence it forms a different feature vector\n",
        "\n",
        "print(model.get_word_vector('Go')==model.get_word_vector('go'))\n",
        "\n"
      ],
      "metadata": {
        "id": "WgXAIx_5uXpz",
        "outputId": "61e2917d-0074-4475-f1fd-f26ecfe7c992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check how much silmilar those are \n",
        "vec_1 = model.get_word_vector('Go')\n",
        "vec_2 = model.get_word_vector('go')\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(np.expand_dims(vec_1,axis=0),np.expand_dims(vec_2,axis=0))"
      ],
      "metadata": {
        "id": "78U8NKdPwcWJ",
        "outputId": "d13b803f-ca31-4576-c1c6-fbf270e103c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65177125]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors('renault')"
      ],
      "metadata": {
        "id": "ocM1zBYDxvDi",
        "outputId": "79e7b539-6ef1-4584-cff8-683b21bc1b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6608074307441711, 'peugeot'),\n",
              " (0.6138680577278137, 'megane'),\n",
              " (0.5940883755683899, 'vauxhall'),\n",
              " (0.5919476747512817, 'Renault'),\n",
              " (0.5911474227905273, 'skoda'),\n",
              " (0.5885468125343323, 'hyundai'),\n",
              " (0.5834581851959229, 'citroen'),\n",
              " (0.5680468082427979, 'Avantime'),\n",
              " (0.5656760334968567, 'nissan'),\n",
              " (0.5618788599967957, 'clio')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors('nissan')"
      ],
      "metadata": {
        "id": "TtZisxHCx2PY",
        "outputId": "8490cf1a-0f24-464b-e4bb-3efdd60feed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7265346050262451, 'toyota'),\n",
              " (0.7161298394203186, 'hyundai'),\n",
              " (0.7156455516815186, 'nissans'),\n",
              " (0.6977760195732117, 'altima'),\n",
              " (0.6594758629798889, 'subaru'),\n",
              " (0.6574570536613464, 'gxe'),\n",
              " (0.65306556224823, 'bmw'),\n",
              " (0.6498944759368896, 'mazda'),\n",
              " (0.6429039239883423, 'camry'),\n",
              " (0.642418622970581, 'honda')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom domain - Indian Food Receipe"
      ],
      "metadata": {
        "id": "j2N6FUBM7-Ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download file from Kaggle and upload to Python3 google computing (This colab session) "
      ],
      "metadata": {
        "id": "j3lIDhWf8Qov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://www.kaggle.com/datasets/sooryaprakash12/cleaned-indian-recipes-dataset"
      ],
      "metadata": {
        "id": "U0bPkTjYx-kW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "d = files.upload()"
      ],
      "metadata": {
        "id": "v61mNg_yzfB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip archive.zip"
      ],
      "metadata": {
        "id": "8NTZrA7ozmiB",
        "outputId": "bf09d2b4-f2ef-4ae7-f572-c2acdb6093a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive.zip\n",
            "  inflating: Cleaned_Indian_Food_Dataset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/Cleaned_Indian_Food_Dataset.csv\")"
      ],
      "metadata": {
        "id": "F02Yeqhm0Kp3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Duu_IhNN0RVX",
        "outputId": "4e34b1e0-2747-4f77-8e33-4e4842471443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                TranslatedRecipeName  \\\n",
              "0                               Masala Karela Recipe   \n",
              "1                         Spicy Tomato Rice (Recipe)   \n",
              "2  Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
              "3  Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
              "4  Andhra Style Alam Pachadi Recipe - Adrak Chutn...   \n",
              "\n",
              "                               TranslatedIngredients  TotalTimeInMins  \\\n",
              "0  1 tablespoon Red Chilli powder,3 tablespoon Gr...               45   \n",
              "1   2 teaspoon cashew - or peanuts, 1/2 Teaspoon ...               15   \n",
              "2  1 Onion - sliced,1 teaspoon White Urad Dal (Sp...               50   \n",
              "3  1/2 teaspoon Turmeric powder (Haldi),1 tablesp...               45   \n",
              "4   oil - as per use, 1 tablespoon coriander seed...               30   \n",
              "\n",
              "                Cuisine                             TranslatedInstructions  \\\n",
              "0                Indian  To begin making the Masala Karela Recipe,de-se...   \n",
              "1  South Indian Recipes  To make tomato puliogere, first cut the tomato...   \n",
              "2  South Indian Recipes  To begin making the Ragi Vermicelli Recipe, fi...   \n",
              "3                Andhra  To begin making Gongura Chicken Curry Recipe f...   \n",
              "4                Andhra  To make Andhra Style Alam Pachadi, first heat ...   \n",
              "\n",
              "                                                 URL  \\\n",
              "0  https://www.archanaskitchen.com/masala-karela-...   \n",
              "1  https://www.archanaskitchen.com/spicy-tomato-r...   \n",
              "2  https://www.archanaskitchen.com/ragi-vermicell...   \n",
              "3  https://www.archanaskitchen.com/gongura-chicke...   \n",
              "4  https://www.archanaskitchen.com/andhra-style-a...   \n",
              "\n",
              "                                 Cleaned-Ingredients  \\\n",
              "0  salt,amchur (dry mango powder),karela (bitter ...   \n",
              "1  tomato,salt,chickpea lentils,green chilli,rice...   \n",
              "2  salt,rice vermicelli noodles (thin),asafoetida...   \n",
              "3  tomato,salt,ginger,sorrel leaves (gongura),fen...   \n",
              "4  tomato,salt,ginger,red chillies,curry,asafoeti...   \n",
              "\n",
              "                                           image-url  Ingredient-count  \n",
              "0  https://www.archanaskitchen.com/images/archana...                10  \n",
              "1  https://www.archanaskitchen.com/images/archana...                12  \n",
              "2  https://www.archanaskitchen.com/images/archana...                12  \n",
              "3  https://www.archanaskitchen.com/images/archana...                15  \n",
              "4  https://www.archanaskitchen.com/images/archana...                12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-598c101a-e9d0-498b-a002-937b21b2d942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TranslatedRecipeName</th>\n",
              "      <th>TranslatedIngredients</th>\n",
              "      <th>TotalTimeInMins</th>\n",
              "      <th>Cuisine</th>\n",
              "      <th>TranslatedInstructions</th>\n",
              "      <th>URL</th>\n",
              "      <th>Cleaned-Ingredients</th>\n",
              "      <th>image-url</th>\n",
              "      <th>Ingredient-count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Masala Karela Recipe</td>\n",
              "      <td>1 tablespoon Red Chilli powder,3 tablespoon Gr...</td>\n",
              "      <td>45</td>\n",
              "      <td>Indian</td>\n",
              "      <td>To begin making the Masala Karela Recipe,de-se...</td>\n",
              "      <td>https://www.archanaskitchen.com/masala-karela-...</td>\n",
              "      <td>salt,amchur (dry mango powder),karela (bitter ...</td>\n",
              "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spicy Tomato Rice (Recipe)</td>\n",
              "      <td>2 teaspoon cashew - or peanuts, 1/2 Teaspoon ...</td>\n",
              "      <td>15</td>\n",
              "      <td>South Indian Recipes</td>\n",
              "      <td>To make tomato puliogere, first cut the tomato...</td>\n",
              "      <td>https://www.archanaskitchen.com/spicy-tomato-r...</td>\n",
              "      <td>tomato,salt,chickpea lentils,green chilli,rice...</td>\n",
              "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
              "      <td>1 Onion - sliced,1 teaspoon White Urad Dal (Sp...</td>\n",
              "      <td>50</td>\n",
              "      <td>South Indian Recipes</td>\n",
              "      <td>To begin making the Ragi Vermicelli Recipe, fi...</td>\n",
              "      <td>https://www.archanaskitchen.com/ragi-vermicell...</td>\n",
              "      <td>salt,rice vermicelli noodles (thin),asafoetida...</td>\n",
              "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
              "      <td>1/2 teaspoon Turmeric powder (Haldi),1 tablesp...</td>\n",
              "      <td>45</td>\n",
              "      <td>Andhra</td>\n",
              "      <td>To begin making Gongura Chicken Curry Recipe f...</td>\n",
              "      <td>https://www.archanaskitchen.com/gongura-chicke...</td>\n",
              "      <td>tomato,salt,ginger,sorrel leaves (gongura),fen...</td>\n",
              "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Andhra Style Alam Pachadi Recipe - Adrak Chutn...</td>\n",
              "      <td>oil - as per use, 1 tablespoon coriander seed...</td>\n",
              "      <td>30</td>\n",
              "      <td>Andhra</td>\n",
              "      <td>To make Andhra Style Alam Pachadi, first heat ...</td>\n",
              "      <td>https://www.archanaskitchen.com/andhra-style-a...</td>\n",
              "      <td>tomato,salt,ginger,red chillies,curry,asafoeti...</td>\n",
              "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-598c101a-e9d0-498b-a002-937b21b2d942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-598c101a-e9d0-498b-a002-937b21b2d942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-598c101a-e9d0-498b-a002-937b21b2d942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['TranslatedInstructions'][0]"
      ],
      "metadata": {
        "id": "cs4g33ah0VKo",
        "outputId": "65a39171-a663-4f7d-879c-eddbce016721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s\\']',' ', text) # Replacing anything(symbols) which is not word or space by SPACE\n",
        "    text = re.sub(r'[ \\n]+', ' ', text) # Replacing more than one whitespace and new line with SPACE\n",
        "    return text.strip().lower()  # Bring it to lowercase format"
      ],
      "metadata": {
        "id": "ibzVQHB32MWl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Praba']=df['TranslatedInstructions'].apply(preprocess)"
      ],
      "metadata": {
        "id": "fuirBc9U2iXw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Praba'][0]"
      ],
      "metadata": {
        "id": "XzCgYoHI2zky",
        "outputId": "34dead6d-f493-4ecd-b551-682c3cfad5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to begin making the masala karela recipe de seed the karela and slice do not remove the skin as the skin has all the nutrients add the karela to the pressure cooker with 3 tablespoon of water salt and turmeric powder and pressure cook for three whistles release the pressure immediately and open the lids keep aside heat oil in a heavy bottomed pan or a kadhai add cumin seeds and let it sizzle once the cumin seeds have sizzled add onions and saute them till it turns golden brown in color add the karela red chilli powder amchur powder coriander powder and besan stir to combine the masalas into the karela drizzle a little extra oil on the top and mix again cover the pan and simmer masala karela stirring occasionally until everything comes together well turn off the heat transfer masala karela into a serving bowl and serve serve masala karela along with panchmel dal and phulka for a weekday meal with your family'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "VHhr05je25v4",
        "outputId": "a857063e-e889-453e-ed4d-a494c45785d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5938, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting the selected column to csv"
      ],
      "metadata": {
        "id": "UbMYIFQA8cLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('for_fastetxt_train.txt',columns= ['Praba'],header=None,index=False)"
      ],
      "metadata": {
        "id": "8fFGOK_J3S5V"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model \n",
        "\n",
        "To know more : https://fasttext.cc/docs/en/unsupervised-tutorial.html#:~:text=fastText%20provides%20two%20models%20for,word%20according%20to%20its%20context."
      ],
      "metadata": {
        "id": "ADAhYi2r8iOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = fasttext.train_unsupervised('for_fastetxt_train.txt')"
      ],
      "metadata": {
        "id": "rZP7D7yx4-mz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testign the new model"
      ],
      "metadata": {
        "id": "l6gepEp488bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.get_nearest_neighbors('rice')"
      ],
      "metadata": {
        "id": "Ub6lGREd5IcB",
        "outputId": "3b6f0188-3321-4c90-aa4f-e2d7d9b22bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6287487745285034, 'dappalam'),\n",
              " (0.6262947916984558, 'vepampoo'),\n",
              " (0.6185956597328186, 'kappa'),\n",
              " (0.6111569404602051, 'neychoru'),\n",
              " (0.6104965806007385, 'dan'),\n",
              " (0.6078392863273621, 'appalam'),\n",
              " (0.604335606098175, 'cherupayar'),\n",
              " (0.6032244563102722, 'authentic'),\n",
              " (0.5939652919769287, 'payaru'),\n",
              " (0.5922381281852722, 'pirattal')]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.get_nearest_neighbors('kulambu', k= 20)"
      ],
      "metadata": {
        "id": "t4CzPhqx5wk4",
        "outputId": "4e8e9dea-7993-492d-8ac0-3964445fb3da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.9184916019439697, 'ambul'),\n",
              " (0.8820753693580627, 'tambuli'),\n",
              " (0.8733407258987427, 'kopi'),\n",
              " (0.868126630783081, 'poosanikai'),\n",
              " (0.8638516664505005, 'pulusu'),\n",
              " (0.8630598783493042, 'pudalangai'),\n",
              " (0.8593765497207642, 'karamani'),\n",
              " (0.859148383140564, 'kongunadu'),\n",
              " (0.8546851873397827, 'pulissery'),\n",
              " (0.8544163107872009, 'muringakka'),\n",
              " (0.8512568473815918, 'kuzhambu'),\n",
              " (0.8451563119888306, 'udupi'),\n",
              " (0.8450186848640442, 'pirattal'),\n",
              " (0.8447285294532776, 'kumro'),\n",
              " (0.8426192402839661, 'sorakaya'),\n",
              " (0.8425213098526001, 'ambur'),\n",
              " (0.8365226984024048, 'gorikayi'),\n",
              " (0.835997462272644, 'ambe'),\n",
              " (0.8353236317634583, 'kukul'),\n",
              " (0.8314515948295593, 'poricha')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ¨âœ¨âœ¨ Observation âœ¨âœ¨âœ¨\n",
        "\n",
        "> What we understand from the custom model we trained , we can form a embedding in a meaningful way from the train dataaset we feed to the fasttext.\n",
        "\n",
        ">Basically PreEmbedded models are trained on Wikipedia data or google news data or few others. If you knwo that you are building it for your custom domain , fasttext would be right place to start.\n",
        "\n",
        ">get nearesrt neighbors function gurantess us that the embedding vector is being formed in a meaningful by understanding the context in the training data\n",
        "\n",
        "ðŸ’¡"
      ],
      "metadata": {
        "id": "R_2HAr-l6HNQ"
      }
    }
  ]
}